{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eTFY7DQKhXRoIvgAwA25ImPn9GdhFSMx","timestamp":1691904020423}],"authorship_tag":"ABX9TyPfhoNlllz/62IALTCQgBo7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"l_UHiY2R9xL6"}},{"cell_type":"markdown","source":["**This document provides a sequential guide detailing the process I followed to conduct my analysis, accompanied by my annotations.**\n","\n","1. Create 'combined_data' table\n","   (GAC_Cyclistic_project\\Scripts\\SQL\\tables)\n","    1.   create_cyclistic_tables.sql\n","    2.   load_csv_data_monthwise.sql\n","    3.   combine_monthly_data.sql\n","\n","VIEW-- SELECT * FROM combined_data Limit 10;   \n","\n","2. Error checks and adjustments\n","   (GAC_Cyclistic_project\\Scripts\\SQL\\error_checks_adjustments)\n","\n","   Migration checks:\n","      1. migration_validation_record_counts.sql\n","      2. identify_duplicate_rides.sql\n","\n","After creating the combined_data table, loading the data and performing migration validations, I observed the resulting data set and identified a number of corrections and additional table alterations that needed to be performed. I corrected the data type for the ride length column, and determined that having the day of the year in numerical format (1-365) would be useful.\n","\n","\n","   Table adjustments:\n","      1. alter_ride_length_data_type.sql\n","      2. data_enhancement_doy.sql\n","\n","VIEW-- SELECT * FROM combined_data Limit 10;      \n","\n","******************************************************\n","\n","While looking at the data and developing a list of query ideas, I concluded that it was essential to create a dedicated 'holidays' table for the year 2022, tailored specifically to the Chicago area. Given that the dataset originates from this region, having a comprehensive record of holidays pertinent to Chicago would undoubtedly augment the analytical capabilities and contextual relevance of the data.\n","\n","\n","3. Create 'holidays' table\n","   (GAC_Cyclistic_project\\Scripts\\SQL\\tables)\n","    1.   create_holiday_table.sql\n","    2.   holidays_data_load.sql\n","\n","VIEW-- SELECT * FROM holidays Limit 10;  \n","\n","**Creating Backup Tables:**\n","\n","To safeguard data integrity and provide a safety net for potential changes, I will be generating backup tables for both \"combined_data\" and \"holidays.\" This involves duplicating the structure and content of these tables to preserve their original state. Ensuring that both the tables are securely preserved for reference and restoration purposes.\n","\n","\n","4. Create BACKUP tables\n","   (GAC_Cyclistic_project\\Scripts\\SQL\\tables)\n","    1.  create_combined_data_backup\n","    2.  create_holidays_backup\n","\n","**Data Quality Analysis - Total Nulls and Error Percentage**\n","\n","I had conducted an initial examination of the files during the 'phase_one_transform' process, and wanted to identify and document all the  errors found in the dataset. Although these errors or 'null' values have no impact on the subsequent analysis, it was important to acknowledge and record them.\n","\n","**Note: It is worth mentioning the GPS tracking data at this point. A large number of records within this dataset possess incomplete GPS data. These records do not register as errors in the subsequent reports as they are not null values, therefore skewing the data. It is important to highlight that the GPS data is not utilized in this project's context. And while it has not been further investigated at this juncture, potential exploration may occur in the future.\n","\n","\n","\n","5. Error Analysis\n","  1. total_nulls_and_error_analysis.sql\n","\n","      So first, I wanted to look at count of fields with errors, versus count of total fields, and percentage of the whole.\n","\n","  2. count_records_with_nulls.sql\n","\n","      I then moved on the count of records with errors versus the count of total records and percentage of the whole.\n","\n","  3. data_quality_summary_report.sql\n","\n","      I then pivoted the data to get a total of errors per column\n","\n","  4. monthly_error_statistics_query.sql\n","\n","      Expanding on the summary report I removed the columns identified with no errors ** and broke it down with monthly counts against monthly totals with monthly percentages.\n","\n","**Moving into the analysis phase**\n","\n","First I wanted to get some basic information about the data.\n","\n","6. Analysis\n","   (GAC_Cyclistic_project\\Scripts\\SQL\\analysis)\n","\n","   1. total _records_by_month\n","\n","       Although I had previously obtained the total record count by month during the 'phase_one_transformation' process,  I opted to present this information here to ensure a  seamless flow in the data analysis.\n","\n","   2. total_records_by_quarter.sql\n","\n","      With the larger number of riders are in the third quarter, followed by the second quarter, fourth quarter and finishing with the first quarter.\n","\n","   3. total_records_by_season.sql\n","\n","      The trend follows with the seasons. After adjusting between quarter and season, summer has the highest amount of riders, followed by spring, fall and then winter.\n","\n","\n","**From this point forward, I will be segmenting the statistical analysis of the dataset based on the distinction between \"member\" and \"casual\" users**\n","\n","I wanted to see the total counts of members and casual riders for the entire year, along with the percentage difference between these counts. I will also be doing the same for months and seasons.\n","\n","   7. member_casual_user_stats_year.sql\n","   8. member_casual_user_stats_month.sql\n","   7. member_casual_user_stats_season.sql\n","\n","\n","\n","\n","\n"],"metadata":{"id":"T02jQB9C9zIL"}},{"cell_type":"code","source":[],"metadata":{"id":"K5_AxMelYkD7"},"execution_count":null,"outputs":[]}]}